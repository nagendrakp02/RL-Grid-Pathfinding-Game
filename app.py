import streamlit as st
from agent import QLearningAgent
from grid_environment import GridEnvironment

GRID_SIZE = 5
START = (0, 0)
GOAL = (4, 4)
OBSTACLES = [(1, 1), (2, 2)]

if 'agent' not in st.session_state:
    st.session_state.agent = QLearningAgent(GRID_SIZE)
if 'env' not in st.session_state:
    st.session_state.env = GridEnvironment(GRID_SIZE, START, GOAL, OBSTACLES)

def reset():
    st.session_state.agent_pos = START
    st.session_state.total_reward = 0
    st.session_state.game_over = False
    st.session_state.path = [START]

if 'agent_pos' not in st.session_state:
    reset()

st.title("ğŸ§  RL Grid Pathfinding Game")

def render_grid():
    grid = [["â¬œ"] * GRID_SIZE for _ in range(GRID_SIZE)]
    for ox, oy in OBSTACLES:
        grid[ox][oy] = "â¬›"
    gx, gy = GOAL
    grid[gx][gy] = "ğŸ"
    for (x, y) in st.session_state.path[:-1]:
        grid[x][y] = "â€¢"
    ax, ay = st.session_state.agent_pos
    grid[ax][ay] = "ğŸ¤–"
    return grid

col1, col2, _ = st.columns([1,1,6])
with col1:
    st.button("ğŸ” Reset", on_click=reset)
with col2:
    step_pressed = st.button("â¡ï¸ Move Step")

st.subheader("ğŸ—ºï¸ Grid:")
grid = render_grid()
for row in grid:
    st.write(" ".join(row))

if step_pressed and not st.session_state.game_over:
    env = st.session_state.env
    agent = st.session_state.agent
    state = st.session_state.agent_pos

    action = agent.choose_action(state)
    next_state, reward, done = env.step(action)
    agent.learn(state, action, reward, next_state)

    st.session_state.agent_pos = next_state
    st.session_state.path.append(next_state)
    st.session_state.total_reward += reward
    st.session_state.game_over = done

st.subheader("ğŸ“Š Game Info:")
st.write(f"ğŸ“ Current Position: `{st.session_state.agent_pos}`")
st.write(f"ğŸ›¤ï¸ Path Taken: `{st.session_state.path}`")
st.write(f"ğŸ’° Total Reward: `{st.session_state.total_reward}`")

if st.session_state.game_over:
    st.success("ğŸ‰ Goal Reached! The agent has learned an optimal path!")
